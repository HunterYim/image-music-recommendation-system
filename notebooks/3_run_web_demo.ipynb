{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyOAC9aaNpePaYd7riePDPRw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. ì‚¬ì „ ì¤€ë¹„ í•­ëª© (ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ)\n"," - 2_recommendation_loigic_test.ipynbì˜ ëª¨ë¸ ë° ë°ì´í„° ë¡œë”© ë¶€ë¶„ì„ ì›¹ ë°ëª¨ ë²„ì „ì— ë§ê²Œ ìˆ˜ì •í•˜ì—¬ ì‚¬ìš©"],"metadata":{"id":"1wwstv1KJaUr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nePH4OmDqSvM"},"outputs":[],"source":["# --- 1. í™˜ê²½ ì„¤ì • ---\n","\n","# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n","!pip install -q transformers accelerate bitsandbytes\n","!pip install -q ftfy regex tqdm\n","!pip install -q git+https://github.com/openai/CLIP.git\n","!pip install -q librosa\n","\n","# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n","import os\n","import io\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from torch import nn\n","from PIL import Image\n","from typing import List\n","from google.colab import files\n","from IPython.display import Audio, display\n","from pprint import pprint\n","from transformers import (\n","    ClapModel, ClapProcessor,\n","    Blip2ForConditionalGeneration, AutoProcessor,\n","    InstructBlipForConditionalGeneration,\n","    CLIPModel, CLIPProcessor as HFCLIPProcessor\n",")\n","\n","# 3. Google Drive ë§ˆìš´íŠ¸\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","print(\"âœ… 1. í™˜ê²½ ì„¤ì • ì™„ë£Œ\")"]},{"cell_type":"code","source":["# --- 2. ê²½ë¡œ ë° ì „ì—­ ì„¤ì • ---\n","\n","# === ê¸°ë³¸ ì„¤ì • ===\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","DTYPE_TORCH = torch.float16 if DEVICE == \"cuda\" else torch.float32\n","TOPK = 3  # ì¶”ì²œí•  íŠ¸ë™ ê°œìˆ˜\n","\n","# === íŒŒì¼ ê²½ë¡œ (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •) ===\n","MUSIC_EMB_PATH = \"/content/drive/MyDrive/Jamendo_Embeddings_Final/song_embeds.npy\"\n","MUSIC_META_PATH = \"/content/drive/MyDrive/Jamendo_Embeddings_Final/song_paths.csv\"\n","CLIP_EMOTION_CKPT = \"/content/drive/MyDrive/image-music-recommendation-system_final/clip_emotion_classifier.pt\"\n","\n","# === í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •) ===\n","IMAGE_PATHS = [\"/content/drive/MyDrive/Datasets/EmoSet-118K/image/amusement/amusement_00000.jpg\"]\n","\n","# === ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ===\n","# ìŒì•… ì„ë² ë”© ë§Œë“¤ ë•Œ ì“´ ê²ƒê³¼ ë™ì¼í•´ì•¼ í•¨\n","CLAP_CKPT = \"laion/clap-htsat-unfused\"\n","\n","# ì§§ì€ ìº¡ì…˜\n","BLIP2_CKPT = \"Salesforce/blip2-flan-t5-xl\"\n","\n","# ê¸´ ì„¤ëª…\n","INSTRUCTBLIP_CKPT = \"Salesforce/instructblip-flan-t5-xl\"\n","\n","# ê°ì • ì¶”ì¶œ CLIP ëª¨ë¸\n","CLIP_CHECKPOINT = \"openai/clip-vit-base-patch32\"\n","\n","# === ê°ì • í´ë˜ìŠ¤ ë¼ë²¨ ===\n","EMO_LABELS = [\"amusement\", \"anger\", \"awe\", \"contentment\", \"disgust\", \"excitement\", \"fear\", \"sadness\"]\n","\n","print(f\"âœ… 2. ì„¤ì • ì™„ë£Œ. Device: {DEVICE}, DType: {DTYPE_TORCH}\")"],"metadata":{"id":"xnOy_kK_smON"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 3. ëª¨ë“  AI ëª¨ë¸ ë¡œë“œ ---\n","\n","# (1) CLAP\n","clap_model = ClapModel.from_pretrained(CLAP_CKPT).to(DEVICE).eval()\n","clap_processor = ClapProcessor.from_pretrained(CLAP_CKPT)\n","print(\"âœ… CLAP ë¡œë“œ ì™„ë£Œ.\")\n","\n","# (2) BLIP-2\n","blip2_processor = AutoProcessor.from_pretrained(BLIP2_CKPT)\n","blip2_model = Blip2ForConditionalGeneration.from_pretrained(BLIP2_CKPT, torch_dtype=DTYPE_TORCH, device_map=\"auto\").eval()\n","print(\"âœ… BLIP-2 ë¡œë“œ ì™„ë£Œ.\")\n","\n","# (3) InstructBLIP\n","instruct_processor = AutoProcessor.from_pretrained(INSTRUCTBLIP_CKPT)\n","instruct_model = InstructBlipForConditionalGeneration.from_pretrained(INSTRUCTBLIP_CKPT, torch_dtype=DTYPE_TORCH, device_map=\"auto\").eval()\n","print(\"âœ… InstructBLIP ë¡œë“œ ì™„ë£Œ.\")\n","\n","# (4) Fine-tuned CLIP Emotion Classifier\n","class CLIPEmotionHead(nn.Module):\n","    def __init__(self, in_dim, num_classes):\n","        super().__init__()\n","        self.classifier = nn.Linear(in_dim, num_classes)\n","    def forward(self, x): return self.classifier(x)\n","\n","# --- CLIP ë°±ë³¸ ë¡œë“œ ---\n","clip_backbone = CLIPModel.from_pretrained(CLIP_CHECKPOINT, torch_dtype=DTYPE_TORCH).to(DEVICE).eval()\n","clip_proc = HFCLIPProcessor.from_pretrained(CLIP_CHECKPOINT)\n","\n","# --- Emotion Head ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ ---\n","IN_DIM = clip_backbone.config.projection_dim\n","emotion_head = CLIPEmotionHead(in_dim=IN_DIM, num_classes=len(EMO_LABELS)).to(DEVICE, dtype=DTYPE_TORCH).eval()\n","\n","# ì²´í¬í¬ì¸íŠ¸(.pth)ì—ì„œ ê°€ì¤‘ì¹˜ë¥¼ ê·¸ëŒ€ë¡œ ë¡œë“œ\n","ckpt = torch.load(CLIP_EMOTION_CKPT, map_location=DEVICE)\n","\n","if \"classifier.weight\" in ckpt:\n","    # ëª¨ë¸ ì „ì²´ ë˜ëŠ” í—¤ë“œ ì „ì²´ê°€ ì €ì¥ëœ ê²½ìš°\n","    final_state_dict = {k: v for k, v in ckpt.items() if k.startswith(\"classifier.\")}\n","    emotion_head.load_state_dict(final_state_dict)\n","else:\n","    # ë¶„ë¥˜ê¸° ë¶€ë¶„ë§Œ ì €ì¥ëœ ê²½ìš° (í‚¤ì— 'classifier.' ì ‘ë‘ì‚¬ê°€ ì—†ìŒ)\n","    final_state_dict = {k: v for k, v in ckpt.items() if k.startswith(\"classifier.\")}\n","    if not final_state_dict:\n","        try:\n","             emotion_head.classifier.load_state_dict(ckpt)\n","        except RuntimeError:\n","             final_state_dict = {k.replace(\"classifier.\", \"\"): v for k, v in ckpt.items() if \"classifier.\" in k}\n","             emotion_head.classifier.load_state_dict(final_state_dict)\n","\n","    else:\n","        emotion_head.load_state_dict(final_state_dict)\n","print(\"âœ… CLIP ë¡œë“œ ì™„ë£Œ.\")\n","\n","print(\"âœ… 3. ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")"],"metadata":{"id":"2vtmmGvYvldM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 4. ìŒì•… DB ë¡œë“œ ë° í•µì‹¬ ë¡œì§ í•¨ìˆ˜ ì •ì˜ ---\n","\n","# (1) ìŒì•… DB ë¡œë“œ\n","song_embeds = torch.from_numpy(np.load(MUSIC_EMB_PATH)).float().to(DEVICE)\n","song_meta = pd.read_csv(MUSIC_META_PATH)\n","song_embeds = song_embeds / song_embeds.norm(dim=-1, keepdim=True)\n","print(f\"âœ… ìŒì•… DB ë¡œë“œ ì™„ë£Œ: {len(song_meta)} ê³¡\")\n","\n","# (2) AI íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ë“¤\n","@torch.inference_mode()\n","def predict_emotion(image):\n","    # processor ì¶œë ¥ë„ ëª¨ë¸ dtypeìœ¼ë¡œ ìºìŠ¤íŒ…\n","    inputs = clip_proc(images=image, return_tensors=\"pt\").to(DEVICE, dtype=DTYPE_TORCH)\n","\n","    # CLIP ë¹„ì£¼ì–¼ ì„ë² ë”© (dtype ì¼ì¹˜)\n","    img_feats = clip_backbone.get_image_features(**inputs)    # [1, D], dtype=DTYPE_TORCH\n","\n","    # ë¡œì§“ â†’ ì˜¨ë„ ìŠ¤ì¼€ì¼ â†’ ì†Œí”„íŠ¸ë§¥ìŠ¤\n","    logits = emotion_head(img_feats)                          # [1, C], dtype=DTYPE_TORCH\n","    probs = torch.softmax(logits.float(), dim=-1)[0]          # ì•ˆì •ì„± ìœ„í•´ softmaxë§Œ float32\n","\n","    top_id = torch.argmax(probs).item()\n","    return {\n","        \"label\": EMO_LABELS[top_id],\n","        \"prob\": probs[top_id].item(),\n","        \"all_probs\": probs.cpu().numpy()\n","    }\n","\n","@torch.inference_mode()\n","def blip2_caption(image):\n","    inputs = blip2_processor(images=image, return_tensors=\"pt\").to(DEVICE, DTYPE_TORCH)\n","    out = blip2_model.generate(**inputs, max_new_tokens=30)\n","    return blip2_processor.batch_decode(out, skip_special_tokens=True)[0].strip()\n","\n","@torch.inference_mode()\n","def instructblip_describe(image):\n","    prompt = \"Write a detailed, vivid description of the image focusing on mood, scene, colors, lighting, and context.\"\n","    inputs = instruct_processor(images=image, text=prompt, return_tensors=\"pt\").to(DEVICE, DTYPE_TORCH)\n","    out = instruct_model.generate(**inputs, max_new_tokens=160)\n","    return instruct_processor.batch_decode(out, skip_special_tokens=True)[0].strip()\n","\n","def build_texts_for_image(pil_img):\n","    cap_short = blip2_caption(pil_img)\n","    emo = predict_emotion(pil_img)\n","    cap_combo = f\"This image conveys {emo['label']} and feels like {emo['label']} mood. Caption: {cap_short}\"\n","    cap_long = instructblip_describe(pil_img)\n","    return cap_short, cap_combo, cap_long, emo\n","\n","@torch.inference_mode()\n","def score_all_songs_with_text(text: str):\n","    inputs = clap_processor(text=[text], return_tensors=\"pt\", padding=True).to(DEVICE)\n","    text_emb = clap_model.get_text_features(**inputs)\n","    text_emb = text_emb / text_emb.norm(dim=-1, keepdim=True)\n","    sims = text_emb @ song_embeds.T\n","    return sims.squeeze(0)\n","\n","def topk_emotions_from_probs(prob_array, labels, k=3):\n","    idx = np.asarray(prob_array).argsort()[::-1][:k]\n","    return [(labels[i], float(prob_array[i])) for i in idx]\n","\n","def show_topk_audio(sims_1d, k=3, title=\"Results\"):\n","    sims_cpu = sims_1d.detach().float().cpu().numpy()\n","    idx = sims_cpu.argsort()[::-1][:k]\n","\n","    print(f\"\\n== {title} (Top-{k}) ==\")\n","\n","    for r, i in enumerate(idx, start=1):\n","        score = float(sims_cpu[i])\n","        row = song_meta.iloc[i]\n","\n","        full_path = row.get(\"path\", \"N/A\")\n","\n","        try:\n","            dir_path, file_name = os.path.split(full_path)\n","            parent_dir_path, dir_name = os.path.split(dir_path)\n","            meaningful_path = f\"{dir_name}/{file_name}\"\n","        except:\n","            meaningful_path = full_path # ê²½ë¡œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ê²½ë¡œ í‘œì‹œ\n","\n","        print(f\"[{r:02d}] score={score:.3f} | title='{meaningful_path}'\")\n","\n","        try:\n","            display(Audio(filename=full_path))\n","        except Exception as e:\n","            print(f\"  (Audio preview failed for path: {full_path}. Error: {e})\")\n","\n","@torch.no_grad()\n","def clap_text_embed(texts: List[str]) -> torch.Tensor:\n","    inputs = clap_processor(text=texts, return_tensors=\"pt\", padding=True, truncation=True).to(DEVICE)\n","    text_feats = clap_model.get_text_features(**inputs)  # [B, D]\n","    return l2norm(text_feats)\n","\n","# (3) ë©”ì¸ ë°ëª¨ í•¨ìˆ˜\n","def demo_recommend_3plus3(pil_image, lam=0.6, top_k=3):\n","    # í…ìŠ¤íŠ¸ ì¿¼ë¦¬ 3ì¢… ìƒì„±\n","    cap_short, cap_combo, cap_long, emo = build_texts_for_image(pil_image)\n","\n","    # ê²°ê³¼ í—¤ë” ì¶œë ¥\n","    print(\"=\"*100)\n","    print(f\"[IMAGE ANALYSIS RESULTS]\")\n","    # top-3 ê°ì • í¬ë§¤íŒ…\n","    emo_top3 = topk_emotions_from_probs(emo[\"all_probs\"], EMO_LABELS, k=3)\n","    print(\"CLIP Emotions (Top-3):\", \", \".join([f\"{e}({p:.2f})\" for e,p in emo_top3]))\n","    print(f\"BLIP-2 Caption: {cap_short}\")\n","    print(f\"InstructBLIP Caption (Long): {cap_long}\")\n","    print(\"=\"*100)\n","\n","    # Stage-1 ì¶”ì²œ (BLIP2+CLIP ìœµí•© ì¿¼ë¦¬)\n","    s1 = score_all_songs_with_text(cap_combo)\n","    show_topk_audio(s1, k=top_k, title=\"â–¶ Stage-1 Recommendations (Emotion + Facts)\")\n","\n","    # Stage-2 ì¬ë­í‚¹ (InstructBLIP ìƒì„¸ ë¬˜ì‚¬ ì¶”ê°€)\n","    s2 = score_all_songs_with_text(cap_long)\n","    fused_scores = lam * s1 + (1.0 - lam) * s2\n","    show_topk_audio(fused_scores, k=top_k, title=f\"â–¶ Stage-2 Re-ranked Recommendations (Context Enhanced)\")\n","\n","print(\"âœ… 4. í•µì‹¬ ë¡œì§ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"],"metadata":{"id":"S4CwQfHTx2Vr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. ì‹¤ì œ ì›¹ ë°ëª¨ ì‹¤í–‰ ë¶€ë¶„"],"metadata":{"id":"W6ddeNmZJfvo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3g6RmBCIndw"},"outputs":[],"source":["# --- 1. ì›¹ ì„œë²„ ë° í„°ë„ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤€ë¹„ ---\n","\n","# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n","!pip install -q fastapi uvicorn[standard] python-multipart nest_asyncio starlette cloudflared\n","\n","# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n","import nest_asyncio\n","import uvicorn\n","import threading\n","import time\n","import re\n","import subprocess\n","\n","from fastapi import FastAPI, UploadFile, File, Response\n","from fastapi.responses import HTMLResponse, JSONResponse\n","from fastapi.middleware.cors import CORSMiddleware\n","from fastapi.staticfiles import StaticFiles\n","\n","# 3. ë¹„ë™ê¸° í™˜ê²½ ì„¤ì •\n","# Colab/Jupyter í™˜ê²½ì—ì„œ uvicorn ì„œë²„ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•´ í•„ìš”\n","nest_asyncio.apply()\n","\n","# 4. ì „ì—­ ë° ê¸°íƒ€ ì„¤ì •\n","AUDIO_ROOT = \"/content/drive/MyDrive/Datasets\"\n","assert os.path.exists(AUDIO_ROOT), f\"AUDIO_ROOT not found: {AUDIO_ROOT}\"\n","\n","# CSV ì»¬ëŸ¼ëª… ìœ ì—°í•˜ê²Œ ì°¾ê¸°\n","PATH_COL = next((c for c in [\"path\",\"filepath\",\"file\"] if c in song_meta.columns), song_meta.columns[0])\n","TITLE_COL = next((c for c in [\"title\",\"name\"] if c in song_meta.columns), None)\n","\n","print(\"âœ… 1. ì›¹ ë°ëª¨ í™˜ê²½ ì„¤ì • ì™„ë£Œ.\")"]},{"cell_type":"code","source":["# --- 2. HTML UI ì •ì˜ ---\n","# ê°„ë‹¨í•œ ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ê²°ê³¼ í‘œì‹œ í˜ì´ì§€\n","INDEX_HTML = \"\"\"\n","<!doctype html><html lang=\"ko\"><head>\n","<meta charset=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"/>\n","<title>ì‚¬ì§„-ìŒì•… ì¶”ì²œ</title>\n","<link rel=\"icon\" type=\"image/png\" href=\"/static/icon4.png\">\n","<style>\n"," body{\n","   font-family:system-ui,sans-serif;\n","   max-width:920px;margin:0 auto;padding:0;\n","   background:#f9fafc;\n"," }\n"," header{\n","   background:#002b5b;\n","   color:white;\n","   padding:20px 24px;\n","   border-radius:0 0 20px 20px;\n","   text-align:center;\n"," }\n"," .card{\n","   background:white;\n","   border:1px solid #ddd;\n","   border-radius:14px;\n","   padding:16px;\n","   margin:16px 0;\n","   box-shadow:0 2px 6px rgba(0,0,0,0.08);\n"," }\n"," .song{\n","   border:1px solid #eee;\n","   border-radius:12px;\n","   padding:10px;\n","   margin:8px 0;\n"," }\n"," .muted{color:#666;font-size:14px}\n"," button{\n","   padding:10px 16px;\n","   border:1px solid #ccc;\n","   border-radius:10px;\n","   cursor:pointer;\n","   background:#004080;\n","   color:white;\n"," }\n"," button:hover{\n","   background:#0055aa;\n"," }\n"," #preview{\n","   max-width:280px;\n","   border:1px solid #eee;\n","   border-radius:10px;\n","   margin-top:10px;\n"," }\n"," footer{\n","   text-align:center;\n","   padding:20px;\n","   font-size:14px;\n","   color:#888;\n","   margin-top:40px;\n","   border-top:1px solid #ddd;\n"," }\n","</style>\n","</head><body>\n","<header>\n","  <h1> AI ì´ë¯¸ì§€ ìŒì•… ì¶”ì²œ ì‹œìŠ¤í…œ </h1>\n","  <p>HKNU AI, Music and Photography</p>\n","</header>\n","\n","<div class=\"card\">\n","  <input id=\"file\" type=\"file\" accept=\"image/*\"/>\n","  <button id=\"btn\" type=\"button\">ì¶”ì²œ ë°›ê¸°</button>\n","  <span id=\"msg\" class=\"muted\"></span>\n","  <div style=\"margin-top:10px; color:#aa0000; font-size:14px;\">\n","    âš ï¸ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ëŠ” ì„œë²„ì— ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n","  </div>\n","  <div><img id=\"preview\" src=\"\"/></div>\n","</div>\n","\n","<div class=\"card\">\n","  <h3>ìš”ì•½</h3>\n","  <div id=\"summary\"></div>\n","</div>\n","\n","<div class=\"card\">\n","  <h3>1ë‹¨ê³„: CLIP + BLIP2 ì´ë¯¸ì§€ ë¶„ìœ„ê¸° ê¸°ë°˜ ìŒì•… ì¶”ì²œ (Top-3)</h3>\n","  <div id=\"stage1\"></div>\n","</div>\n","\n","<div class=\"card\">\n","  <h3>2ë‹¨ê³„: InstructBLIP ì„¤ëª… í™•ì¥ ê¸°ë°˜ ì¬ì¶”ì²œ (Top-3)</h3>\n","  <div id=\"stage2\"></div>\n","</div>\n","\n","<footer>Â© HKNU AI, Music and Photography </footer>\n","\n","<script>\n","const $ = id => document.getElementById(id);\n","const file = $(\"file\"), btn = $(\"btn\"), preview = $(\"preview\"), msg = $(\"msg\");\n","const summary = $(\"summary\"), stage1Box = $(\"stage1\"), stage2Box = $(\"stage2\");\n","\n","file.addEventListener(\"change\", () => {\n","  const f = file.files[0];\n","  if (!f) { preview.src=\"\"; msg.textContent=\"\"; return; }\n","  preview.src = URL.createObjectURL(f);\n","  msg.textContent = `${f.name} (${Math.round(f.size/1024)} KB)`;\n","});\n","\n","async function safeJson(r){\n","  const txt = await r.text();\n","  try { return JSON.parse(txt); } catch { return { ok:false, error: txt }; }\n","}\n","\n","btn.addEventListener(\"click\", async (e) => {\n","  e.preventDefault();\n","  const f = file.files[0];\n","  if (!f) { alert(\"ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”.\"); return; }\n","\n","  summary.innerHTML = \"ë¶„ì„ ì¤‘â€¦\";\n","  stage1Box.innerHTML = \"\";\n","  stage2Box.innerHTML = \"\";\n","\n","  const fd = new FormData();\n","  fd.append(\"file\", f, f.name);\n","\n","  try {\n","    const r = await fetch(location.origin + \"/recommend\", { method:\"POST\", body: fd });\n","    const data = await safeJson(r);\n","    if (!r.ok || !data.ok){\n","      const m = (data && data.error) ? `${data.error} (stage=${data.stage||\"?\"})` : `HTTP ${r.status}`;\n","      alert(\"ì„œë²„ ì˜¤ë¥˜: \" + m);\n","      console.error(\"server error:\", data);\n","      return;\n","    }\n","\n","    summary.innerHTML = `\n","      <div><b>Emotion:</b> ${data.emotion.label} (p=${data.emotion.prob.toFixed(3)})</div>\n","      <div><b>BLIP2 caption:</b> ${data.texts.blip2_caption}</div>\n","      <div><b>BLIP2+CLIP caption:</b> ${data.texts.clip_plus_blip2}</div>\n","      <div><b>InstructBLIP expanded:</b> ${data.texts.instruct_expanded}</div>\n","    `;\n","\n","    const render = arr => arr.map(x => `\n","      <div class=\"song\">\n","        <div><b>${x.title || \"(no title)\"}</b></div>\n","        <div class=\"muted\">score=${x.score.toFixed(4)}</div>\n","        ${x.preview_url ? `<audio controls src=\"${x.preview_url}\"></audio>` : `<div class=\"muted\">ë¯¸ë¦¬ë“£ê¸° URL ì—†ìŒ</div>`}\n","        <div class=\"muted\">${x.path}</div>\n","      </div>\n","    `).join(\"\");\n","\n","    stage1Box.innerHTML = render(data.stage1);\n","    stage2Box.innerHTML = render(data.stage2);\n","\n","  } catch (e) {\n","    console.error(e);\n","    alert(\"ìš”ì²­ ì‹¤íŒ¨: \" + e.message);\n","  }\n","});\n","</script>\n","</body></html>\n","\"\"\"\n","\n","print(\"âœ… 2. HTML UI ì •ì˜ ì™„ë£Œ.\")"],"metadata":{"id":"EHJrlXfHzgXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 3. ì›¹ ì„œë²„ìš© í—¬í¼ í•¨ìˆ˜ ì •ì˜ ---\n","\n","# --- í—¬í¼ í•¨ìˆ˜ ---\n","def l2norm(x: torch.Tensor, eps: float = 1e-8):\n","    return x / (x.norm(dim=-1, keepdim=True) + eps)\n","\n","def _to_py(x):\n","    if isinstance(x, (np.floating,)): return float(x)\n","    if isinstance(x, (np.integer,)):  return int(x)\n","    if isinstance(x, (np.bool_,)):    return bool(x)\n","    return x\n","\n","def to_media_url(path: str) -> str:\n","  if re.match(r\"^https?://\", str(path)):\n","        return str(path)\n","  p = os.path.abspath(str(path))\n","  root = os.path.abspath(AUDIO_ROOT)\n","  if p.startswith(root):\n","      rel = p[len(root):].lstrip(os.sep)\n","      return f\"/media/{rel}\"\n","  return \"\"\n","\n","@torch.inference_mode()\n","def score_all_songs_with_text(text: str) -> torch.Tensor:\n","    emb = clap_text_embed([text]).to(song_embeds.device)\n","    emb = emb / (emb.norm(dim=-1, keepdim=True) + 1e-8)\n","    sims = emb @ song_embeds.T          # [1,N]\n","    return sims.squeeze(0)              # [N]\n","\n","def topk_block(scores_1d: torch.Tensor, k: int = 3):\n","    sims = scores_1d.detach().float().cpu().numpy()\n","    idx = sims.argsort()[::-1][:k]\n","    out = []\n","    for r, i in enumerate(idx, start=1):\n","        score = float(sims[i])\n","        row = song_meta.iloc[i]\n","        path = str(row[PATH_COL])\n","        if TITLE_COL is None or pd.isna(row.get(TITLE_COL, None)):\n","            base = os.path.basename(path)\n","            title = os.path.splitext(base)[0]\n","        else:\n","            title = str(row[TITLE_COL])\n","        out.append({\n","            \"rank\": r,\n","            \"index\": int(i),\n","            \"score\": score,\n","            \"title\": title,\n","            \"path\": path,\n","            \"preview_url\": to_media_url(path),\n","        })\n","    return out\n","\n","print(\"âœ… 3. ì›¹ ì„œë²„ìš© í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ.\")"],"metadata":{"id":"7WhevwyOJO61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 4. FastAPI ì›¹ ì„œë²„ ë° Cloudflare Tunnel ì‹¤í–‰ ---\n","\n","app = FastAPI(title=\"Imageâ†’Music Recommendation API\")\n","app.add_middleware(CORSMiddleware, allow_origins=[\"*\"], allow_credentials=True, allow_methods=[\"*\"], allow_headers=[\"*\"])\n","app.mount(\"/media\", StaticFiles(directory=AUDIO_ROOT), name=\"media\")\n","\n","@app.exception_handler(Exception)\n","async def global_exception_handler(request, exc):\n","    import traceback; traceback.print_exc()\n","    return JSONResponse(status_code=500, content={\"ok\": False, \"error\": str(exc)})\n","\n","@app.get(\"/\", response_class=HTMLResponse)\n","def home():\n","  return HTMLResponse(INDEX_HTML)\n","\n","@app.post(\"/recommend\")\n","async def recommend(file: UploadFile = File(...)):\n","    stage = \"start\"\n","    try:\n","        # 0) ì´ë¯¸ì§€ ë¡œë”©\n","        stage = \"load_image\"\n","        img = Image.open(io.BytesIO(await file.read())).convert(\"RGB\")\n","\n","        # 1) í…ìŠ¤íŠ¸ ìƒì„±\n","        stage = \"build_texts_for_image\"\n","        cap_short, cap_combo, cap_long, emo = build_texts_for_image(img)\n","\n","        # 2) Stage-1 ì ìˆ˜ (BLIP2+CLIP cap_combo)\n","        stage = \"stage1\"\n","        s1 = score_all_songs_with_text(cap_combo)\n","\n","        # 3) Stage-2 ì ìˆ˜ (Î»Â·s1 + (1-Î»)Â·s2)\n","        stage = \"stage2\"\n","        lam = 0.0\n","        s2 = score_all_songs_with_text(cap_long)\n","        fused = lam * s1 + (1.0 - lam) * s2\n","\n","        # 4) ìƒìœ„ 3ê°œ ë½‘ê¸° â†’ JSON\n","        TOPK = 3\n","        top1 = topk_block(s1, k=TOPK)\n","        top2 = topk_block(fused, k=TOPK)\n","\n","        payload = {\n","            \"ok\": True,\n","            \"emotion\": {\"label\": str(emo[\"label\"]), \"prob\": float(_to_py(emo[\"prob\"]))},\n","            \"texts\": {\n","                \"blip2_caption\": str(cap_short),\n","                \"clip_plus_blip2\": str(cap_combo),\n","                \"instruct_expanded\": str(cap_long),\n","            },\n","            \"stage1\": top1,\n","            \"stage2\": top2,\n","        }\n","        return JSONResponse(payload, media_type=\"application/json\")\n","    except Exception as e:\n","        import traceback; traceback.print_exc()\n","        return JSONResponse({\"ok\": False, \"stage\": stage, \"error\": str(e)}, status_code=500)\n","\n","print(\"âœ… 4. FastAPI ì›¹ ì„œë²„ ë° Cloudflare Tunnel ì‹¤í–‰ ì™„ë£Œ.\")"],"metadata":{"id":"HgHg5UouKz4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 5. ì„œë²„ ë° í„°ë„ ì‹¤í–‰ ---\n","PORT = 8001\n","\n","# (1) cloudflared ì„¤ì¹˜\n","if not os.path.exists('/usr/local/bin/cloudflared'):\n","    print(\"Installing cloudflared...\")\n","    !wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb -O cloudflared.deb\n","    !sudo dpkg -i cloudflared.deb\n","    print(\"cloudflared installed.\")\n","\n","# (2) uvicorn ì„œë²„ë¥¼ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰\n","def run_server():\n","    uvicorn.run(app, host=\"0.0.0.0\", port=PORT, log_level=\"info\")\n","\n","server_thread = threading.Thread(target=run_server, daemon=True)\n","server_thread.start()\n","print(f\"FastAPI server started in background on port {PORT}.\")\n","time.sleep(4) # ì„œë²„ê°€ ì‹œì‘ë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°\n","\n","# (3) Cloudflare Tunnelì„ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰í•˜ê³  ë¡œê·¸ íŒŒì¼ì— ì €ì¥\n","# nohup: í„°ë¯¸ë„ ì—°ê²°ì´ ëŠê²¨ë„ í”„ë¡œì„¸ìŠ¤ë¥¼ ê³„ì† ì‹¤í–‰\n","# > cloudflared.log: ëª¨ë“  ì¶œë ¥ì„ cloudflared.log íŒŒì¼ì— ì €ì¥\n","# 2>&1: í‘œì¤€ ì˜¤ë¥˜ë„ í‘œì¤€ ì¶œë ¥ìœ¼ë¡œ ë¦¬ë””ë ‰ì…˜\n","# &: ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰\n","print(\"\\nStarting Cloudflare Tunnel in the background...\")\n","!nohup cloudflared tunnel --url http://localhost:{PORT} --no-autoupdate > cloudflared.log 2>&1 &\n","time.sleep(3) # í„°ë„ì´ ì‹œì‘ë˜ê³  ë¡œê·¸ê°€ ê¸°ë¡ë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°\n","print(\"Cloudflare Tunnel is running.\")\n","\n","# (4) ë¡œê·¸ íŒŒì¼ì—ì„œ í¼ë¸”ë¦­ URL ì¶”ì¶œ\n","print(\"\\nSearching for public URL in logs...\")\n","public_url = None\n","for i in range(10): # ìµœëŒ€ 10ì´ˆê°„ URLì„ ì°¾ê¸° ìœ„í•´ ì‹œë„\n","    with open('cloudflared.log', 'r') as f:\n","        for line in f:\n","            match = re.search(r\"https://[-a-zA-Z0-9]+\\.trycloudflare\\.com\", line)\n","            if match:\n","                public_url = match.group(0)\n","                break\n","    if public_url:\n","        break\n","    time.sleep(1)\n","\n","if public_url:\n","    print(\"\\n\" + \"=\"*50)\n","    print(\" âœ… Web Demo is Live!\")\n","    print(f\"ğŸ‘‡ğŸ‘‡ğŸ‘‡ Click this public URL to access your demo ğŸ‘‡ğŸ‘‡ğŸ‘‡\")\n","    print(f\"      {public_url}\")\n","    print(\"=\"*50)\n","else:\n","    print(\"\\nâŒ Could not find the public URL.\")\n","    print(\"   Please check the 'cloudflared.log' file for errors:\")\n","    !cat cloudflared.log"],"metadata":{"id":"uruMUmLkQmk-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- requirements.txt ìƒì„± ---\n","print(\"Generating requirements.txt based on the current environment...\")\n","\n","!pip freeze | grep -E 'transformers|torch|pandas|numpy|Pillow|matplotlib|seaborn|scikit-learn|accelerate|bitsandbytes|ftfy|regex|librosa|huggingface-hub|fastapi|uvicorn|python-multipart|nest-asyncio|starlette|cloudflared|clip' > requirements.txt\n","\n","print(\"\\n--- Content of requirements.txt ---\")\n","!cat requirements.txt\n","\n","# ìƒì„±ëœ íŒŒì¼ì„ Google Driveì— ì €ì¥\n","!cp requirements.txt \"/content/drive/MyDrive/image-music-recommendation-system_final/\""],"metadata":{"id":"OQFytx0rCB21"},"execution_count":null,"outputs":[]}]}