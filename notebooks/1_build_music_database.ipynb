{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyPp6JnAMddBPOEqb1lABFti"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# --- 0. Numpy ë²„ì „ ë³€ê²½ ---\n","# í•´ë‹¹ ì‰˜ ì‹¤í–‰ í›„ [ëŸ°íƒ€ì„] - [ì„¸ì…˜ ë‹¤ì‹œ ì‹œì‘]ì„ í•´ì•¼ í•¨\n","print(\"Pinning NumPy to a stable version...\")\n","!pip install numpy==1.26.4\n","\n","print(f\"\\nâœ… 0. Numpy ì„¤ì¹˜ ì™„ë£Œ (ì„¸ì…˜ì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”)\")"],"metadata":{"id":"UPXVw3j86MHx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RQ97TylNkhY"},"outputs":[],"source":["# --- 1. í™˜ê²½ ì„¤ì • ---\n","\n","# 1. ì›ë˜ ì½”ë“œì—ì„œ ì‚¬ìš©í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n","print(\"Installing necessary libraries...\")\n","!pip install -q laion-clap torch torchaudio faiss-cpu pandas tqdm\n","\n","# 2. ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n","import os\n","import torch\n","import numpy as np\n","import pandas as pd\n","import torchaudio\n","import faiss\n","from torch.utils.data import Dataset, DataLoader\n","from laion_clap import CLAP_Module\n","from tqdm.notebook import tqdm\n","\n","# 3. Google Drive ë§ˆìš´íŠ¸\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","print(\"\\nâœ… 1. í™˜ê²½ ì„¤ì • ì™„ë£Œ\")"]},{"cell_type":"code","source":["# --- 2. ê²½ë¡œ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ---\n","\n","# === ì…ë ¥ ê²½ë¡œ (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •) ===\n","# Jamendo ë°ì´í„°ì…‹ì´ ì €ì¥ëœ Google Driveì˜ ê¸°ë³¸ í´ë” ê²½ë¡œ\n","DRIVE_JAMENDO_BASE_PATH = \"/content/drive/MyDrive/Datasets/jamendo_autotag_mood_low\"\n","# ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ (tsv íŒŒì¼)\n","METADATA_PATH = \"/content/drive/MyDrive/Datasets/jamendo_autotag_mood_low/csv/autotagging_moodtheme.tsv\"\n","\n","# === ì¶œë ¥ ê²½ë¡œ (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •) ===\n","# ìµœì¢… ê²°ê³¼ë¬¼ì„ ì €ì¥í•  Google Drive í´ë” ê²½ë¡œ\n","OUTPUT_DIR = \"/content/drive/MyDrive/Jamendo_Embeddings_Final\"\n","OUTPUT_EMBEDDING_PATH = os.path.join(OUTPUT_DIR, \"jamendo_clap_final.npy\")\n","OUTPUT_METADATA_PATH = os.path.join(OUTPUT_DIR, \"jamendo_clap_final.csv\")\n","OUTPUT_FAISS_PATH = os.path.join(OUTPUT_DIR, \"jamendo_clap_final.faiss\")\n","\n","# === ëª¨ë¸ ë° ì²˜ë¦¬ ì„¤ì • ===\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","BATCH_SIZE = 16\n","SAMPLING_RATE = 48000\n","DURATION_SEC = 30\n","\n","# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","print(f\"âœ… 2. ëª¨ë“  ê²½ë¡œ ë° ì„¤ì • ì™„ë£Œ. Device: {DEVICE}\")"],"metadata":{"id":"jv2GRqjh7aCf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 3. CLAP ëª¨ë¸ ë¡œë“œ ---\n","print(\"Loading CLAP model...\")\n","clap_model = CLAP_Module(enable_fusion=False)\n","clap_model.load_ckpt()\n","clap_model = clap_model.to(DEVICE)\n","clap_model.eval()\n","\n","print(\"âœ… 3. CLAP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")"],"metadata":{"id":"QThmPdYuNPxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 4. ë°ì´í„° ì¤€ë¹„ ---\n","import csv\n","\n","# 1. ë©”íƒ€ë°ì´í„° ë¡œë“œ\n","print(\"Loading metadata and constructing file paths...\")\n","try:\n","    # TSV íŒŒì¼ì„ ì§ì ‘ ì½ì–´ì„œ 'path' ì»¬ëŸ¼ë§Œ ì¶”ì¶œ\n","    paths = []\n","    with open(METADATA_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n","        reader = csv.reader(f, delimiter=\"\\t\")\n","        header = next(reader)\n","        path_index = header.index(\"PATH\") # 'PATH' ì»¬ëŸ¼ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°\n","        for row in reader:\n","            if len(row) > path_index:\n","                paths.append(row[path_index].strip())\n","\n","    # DataFrameìœ¼ë¡œ ë³€í™˜\n","    metadata_df = pd.DataFrame({\"relative_path\": paths})\n","    print(f\"Loaded {len(metadata_df)} paths from TSV.\")\n","\n","except Exception as e:\n","    print(f\"âŒ ERROR: Could not load metadata file. {e}\")\n","    raise\n","\n","# 2. ì ˆëŒ€ ê²½ë¡œ ìƒì„± ë° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n","def get_full_path(rel_path):\n","    # .mp3ë¥¼ .low.mp3ë¡œ ë°”ê¾¸ëŠ” ë¡œì§ í¬í•¨\n","    low_path = rel_path.replace(\".mp3\", \".low.mp3\") if rel_path.endswith(\".mp3\") else rel_path\n","    return os.path.join(DRIVE_JAMENDO_BASE_PATH, low_path)\n","\n","metadata_df['full_path'] = metadata_df['relative_path'].apply(get_full_path)\n","\n","print(\"\\nVerifying file existence...\")\n","file_exists = metadata_df['full_path'].apply(os.path.exists)\n","final_df = metadata_df[file_exists].copy()\n","file_paths = final_df['full_path'].tolist()\n","print(f\"Found {len(final_df)} existing audio files to process.\")\n","\n","\n","# 3. PyTorch Dataset ë° DataLoader ì •ì˜\n","class AudioPathDataset(Dataset):\n","    def __init__(self, paths):\n","        self.paths = paths\n","    def __len__(self): return len(self.paths)\n","    def __getitem__(self, idx): return self.paths[idx]\n","\n","def collate_fn_paths(batch):\n","    return [path for path in batch if path]\n","\n","embedding_dataset = AudioPathDataset(file_paths)\n","embedding_dataloader = DataLoader(embedding_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn_paths)\n","\n","print(\"\\nâœ… 4. ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")"],"metadata":{"id":"ErHgwrKBNTZj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 5. ì„ë² ë”© ìƒì„± ë° ì €ì¥ ---\n","\n","# 1. ê°€ì¤‘ì¹˜ ì ìš© ì„ë² ë”© í•¨ìˆ˜\n","@torch.inference_mode()\n","def embed_audio_weighted(path, model, sr=48000):\n","    try:\n","        waveform, orig_sr = torchaudio.load(path)\n","        if orig_sr != sr:\n","            waveform = torchaudio.functional.resample(waveform, orig_sr, sr)\n","\n","        # 30ì´ˆë³´ë‹¤ ì§§ìœ¼ë©´ íŒ¨ë”©\n","        if waveform.shape[1] < sr * 30:\n","            waveform = torch.nn.functional.pad(waveform, (0, sr * 30 - waveform.shape[1]))\n","        else:\n","            waveform = waveform[:, :sr*30]\n","\n","        first_10 = waveform[:, :sr*10]\n","        next_20  = waveform[:, sr*10:sr*30]\n","\n","        emb_10 = model.get_audio_embedding_from_data(x=first_10.to(device), use_tensor=True)\n","        emb_20 = model.get_audio_embedding_from_data(x=next_20.to(device), use_tensor=True)\n","        weighted_emb = (2 * emb_10 + emb_20) / 3\n","        return weighted_emb.cpu().numpy()\n","    except Exception as e:\n","        print(f\"âŒ Failed to process {os.path.basename(path)}: {e}\")\n","        return None\n","\n","# 2. ì„ë² ë”© ìƒì„± ë£¨í”„ (ì²´í¬í¬ì¸íŠ¸ ê¸°ëŠ¥ í¬í•¨)\n","embeddings = []\n","valid_paths = []\n","CHECKPOINT_INTERVAL = 1000 # 1000ê°œ íŒŒì¼ë§ˆë‹¤ ì €ì¥ (ì¡°ì ˆ ê°€ëŠ¥)\n","\n","print(f\"--- Starting weighted embedding generation for {len(file_paths)} tracks ---\")\n","progress_bar = tqdm(embedding_dataloader, desc=\"Generating Embeddings\")\n","\n","for i, path_batch in enumerate(progress_bar):\n","    for path in path_batch:\n","        emb = embed_audio_weighted(path, clap_model)\n","        if emb is not None:\n","            embeddings.append(emb)\n","            valid_paths.append(path)\n","\n","    # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë¡œì§\n","    if (i + 1) * BATCH_SIZE % CHECKPOINT_INTERVAL < BATCH_SIZE:\n","        print(f\"\\nğŸ’¾ Saving checkpoint at {len(valid_paths)} files...\")\n","        np.save(f\"{OUTPUT_EMBEDDING_PATH}.part\", np.vstack(embeddings))\n","        pd.DataFrame({'path': valid_paths}).to_csv(f\"{OUTPUT_METADATA_PATH}.part\", index=False)\n","\n","# 3. ìµœì¢… ê²°ê³¼ ê²°í•© ë° ì €ì¥\n","final_embeddings_np = np.vstack(embeddings)\n","output_meta_df = pd.DataFrame({'path': valid_paths})\n","\n","print(f\"\\nEmbedding generation complete. Final shape: {final_embeddings_np.shape}\")\n","\n","# 4. ìµœì¢… íŒŒì¼ ì €ì¥\n","print(f\"\\nSaving final files to: {OUTPUT_DIR}\")\n","np.save(OUTPUT_EMBEDDING_PATH, final_embeddings_np)\n","output_meta_df.to_csv(OUTPUT_METADATA_PATH, index=False)\n","\n","# 5. FAISS ì¸ë±ìŠ¤ ìƒì„±\n","dim = final_embeddings_np.shape[1]\n","index = faiss.IndexFlatL2(dim)\n","index.add(final_embeddings_np.astype(\"float32\"))\n","faiss.write_index(index, OUTPUT_FAISS_PATH)\n","print(f\"FAISS index created at: {OUTPUT_FAISS_PATH}\")\n","\n","# 6. ì„ì‹œ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì‚­ì œ\n","if os.path.exists(f\"{OUTPUT_EMBEDDING_PATH}.part\"): os.remove(f\"{OUTPUT_EMBEDDING_PATH}.part\")\n","if os.path.exists(f\"{OUTPUT_METADATA_PATH}.part\"): os.remove(f\"{OUTPUT_METADATA_PATH}.part\")\n","\n","\n","print(\"\\nâœ… 5. ëª¨ë“  ì„ë² ë”© ë° ì¸ë±ìŠ¤ íŒŒì¼ ì €ì¥ ì™„ë£Œ\")"],"metadata":{"id":"K7tRVKyFNlap"},"execution_count":null,"outputs":[]}]}